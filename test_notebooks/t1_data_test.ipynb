{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "680b0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单元格 1: 导入\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import webdataset as wds\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 关键：导入PyTorch Geometric\n",
    "import torch.utils.data\n",
    "from torch_geometric.data import Data as PyGData\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader # 或者直接用torch的Dataloader + PyG的collate_fn\n",
    "from torch_geometric.data import Batch as PyGBatch\n",
    "\n",
    "# 从您准备要修改的open-clip目录中导入一些辅助类\n",
    "# 如果您的notebook和open-clip库不在同一个环境下，您可能需要调整sys.path\n",
    "# from open_clip_train.data import DataInfo, SharedEpoch \n",
    "\n",
    "# 为了让Notebook自包含，我们在这里重新定义这些简单的辅助类\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataInfo:\n",
    "    dataloader: torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9a290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 测试环境目录 '/cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment' 已创建。\n",
      "\n",
      "🛠️ 正在生成模拟 AnnData 文件...\n",
      "✅ 模拟 AnnData 文件已保存至: /cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment/metadata/dummy_master_adata.h5ad\n",
      "\n",
      "🛠️ 正在生成模拟 WebDataset 分片...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ead48c6df8947bd8c63498c275c19b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "打包模拟数据:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模拟 WebDataset 分片已保存至: /cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment/shards/shard-000000.tar\n"
     ]
    }
   ],
   "source": [
    "# 单元格 2: 创建模拟数据和文件结构\n",
    "\n",
    "# --- 配置 ---\n",
    "TEST_ENV_DIR = \"/cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment\"\n",
    "SHARDS_DIR = os.path.join(TEST_ENV_DIR, \"shards\")\n",
    "METADATA_DIR = os.path.join(TEST_ENV_DIR, \"metadata\")\n",
    "DUMMY_ADATA_PATH = os.path.join(METADATA_DIR, \"dummy_master_adata.h5ad\")\n",
    "DUMMY_SHARD_PATH_PATTERN = os.path.join(SHARDS_DIR, \"shard-%06d.tar\")\n",
    "\n",
    "NUM_SPOTS = 100\n",
    "NUM_NEIGHBORS = 6\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# --- 清理并创建目录 ---\n",
    "if os.path.exists(TEST_ENV_DIR):\n",
    "    shutil.rmtree(TEST_ENV_DIR)\n",
    "os.makedirs(SHARDS_DIR, exist_ok=True)\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "print(f\"✅ 测试环境目录 '{TEST_ENV_DIR}' 已创建。\")\n",
    "\n",
    "# --- 1. 生成模拟AnnData文件 ---\n",
    "print(\"\\n🛠️ 正在生成模拟 AnnData 文件...\")\n",
    "spot_ids = [f\"DUMMY_SPOT_{i}\" for i in range(NUM_SPOTS)]\n",
    "adata = anndata.AnnData(X=np.random.rand(NUM_SPOTS, 10)) # 伪基因表达数据\n",
    "adata.obs_names = spot_ids\n",
    "adata.obs['sample_id'] = 'DUMMY_SAMPLE'\n",
    "# 为每个spot生成指向即将创建的文件的路径\n",
    "adata.obs['image_path'] = [os.path.join(SHARDS_DIR, f\"{sid}.png\") for sid in spot_ids]\n",
    "adata.obs['sentence_path'] = [os.path.join(SHARDS_DIR, f\"{sid}.txt\") for sid in spot_ids]\n",
    "adata.obsm['spatial'] = np.random.rand(NUM_SPOTS, 2) * 1000 # 伪空间坐标\n",
    "\n",
    "# 创建一个简单的k-NN图\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "connectivity_matrix = kneighbors_graph(adata.obsm['spatial'], NUM_NEIGHBORS, mode='connectivity', include_self=False)\n",
    "adata.obsp['spatial_connectivities'] = connectivity_matrix\n",
    "adata.write_h5ad(DUMMY_ADATA_PATH)\n",
    "print(f\"✅ 模拟 AnnData 文件已保存至: {DUMMY_ADATA_PATH}\")\n",
    "\n",
    "# --- 2. 生成模拟WebDataset分片 ---\n",
    "print(\"\\n🛠️ 正在生成模拟 WebDataset 分片...\")\n",
    "shard_path = DUMMY_SHARD_PATH_PATTERN % 0\n",
    "with wds.TarWriter(shard_path) as sink:\n",
    "    for spot_id in tqdm(spot_ids, desc=\"打包模拟数据\"):\n",
    "        # 创建一个带文字的伪图像\n",
    "        img = Image.new('RGB', IMAGE_SIZE, color = 'black')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        try:\n",
    "            # 尝试加载一个字体，如果失败则使用默认\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 15)\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((10, 10), spot_id, fill='white', font=font)\n",
    "        \n",
    "        # 将图像保存到内存中的字节流\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        image_data = img_byte_arr.getvalue()\n",
    "\n",
    "        # 创建伪基因语句\n",
    "        sentence_data = f\"GENES FOR {spot_id}: GENE_A GENE_B GENE_C\".encode('utf-8')\n",
    "        \n",
    "        # 写入样本\n",
    "        sample = {\"__key__\": spot_id, \"png\": image_data, \"txt\": sentence_data}\n",
    "        sink.write(sample)\n",
    "        \n",
    "        # 同时保存伪PNG和TXT文件，供AnnData中的路径引用\n",
    "        with open(os.path.join(SHARDS_DIR, f\"{spot_id}.png\"), \"wb\") as f_img: f_img.write(image_data)\n",
    "        with open(os.path.join(SHARDS_DIR, f\"{spot_id}.txt\"), \"wb\") as f_txt: f_txt.write(sentence_data)\n",
    "\n",
    "print(f\"✅ 模拟 WebDataset 分片已保存至: {shard_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d056a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 核心数据处理代码已加载到Notebook中。\n"
     ]
    }
   ],
   "source": [
    "# 单元格 3: 复制并粘贴我们正在测试的核心代码\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 这是您计划放在 src/open_clip_train/spaglam_data.py 的代码\n",
    "# -------------------------------------------------------------\n",
    "import logging\n",
    "\n",
    "class SpaGLaMWDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, tar_urls, anndata_path, image_processor, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tar_urls = tar_urls\n",
    "        self.anndata_path = anndata_path\n",
    "        self.image_processor = image_processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.adata = None\n",
    "\n",
    "    def _init_worker(self):\n",
    "        if self.adata is None:\n",
    "            self.adata = sc.read_h5ad(self.anndata_path, backed='r')\n",
    "\n",
    "    def _process_sample(self, sample):\n",
    "        self._init_worker()\n",
    "        center_key = sample['__key__']\n",
    "        \n",
    "        try:\n",
    "            center_idx = self.adata.obs_names.get_loc(center_key)\n",
    "            neighbor_indices = self.adata.obsp['spatial_connectivities'][center_idx].indices\n",
    "            neighbor_keys = self.adata.obs_names[neighbor_indices].tolist()\n",
    "            \n",
    "            all_keys = [center_key] + neighbor_keys\n",
    "            num_nodes = len(all_keys)\n",
    "\n",
    "            paths_df = self.adata.obs.loc[all_keys, ['image_path', 'sentence_path']]\n",
    "            \n",
    "            images, sentences = [], []\n",
    "            for key in all_keys:\n",
    "                if key == center_key:\n",
    "                    img = Image.open(io.BytesIO(sample['png'])).convert(\"RGB\")\n",
    "                    sent = sample['txt'].decode('utf-8')\n",
    "                else:\n",
    "                    img_path, sent_path = paths_df.loc[key]\n",
    "                    try: img = Image.open(img_path).convert(\"RGB\")\n",
    "                    except (FileNotFoundError, OSError): img = Image.new('RGB', (224, 224), color='grey')\n",
    "                    try: \n",
    "                        with open(sent_path, 'r') as f: sent = f.read()\n",
    "                    except (FileNotFoundError, OSError): sent = \"\"\n",
    "                images.append(self.image_processor(img))\n",
    "                sentences.append(sent)\n",
    "\n",
    "            tokenized_texts = self.tokenizer(sentences)\n",
    "            \n",
    "            key_to_local_idx = {key: i for i, key in enumerate(all_keys)}\n",
    "            edge_list = []\n",
    "            center_local_idx = 0\n",
    "            \n",
    "            # 使用AnnData中的邻接矩阵构建局部图\n",
    "            for i, key in enumerate(all_keys):\n",
    "                global_idx = self.adata.obs_names.get_loc(key)\n",
    "                # 获取该节点的邻居的全局索引\n",
    "                row_indices = self.adata.obsp['spatial_connectivities'][global_idx].indices\n",
    "                \n",
    "                for neighbor_global_idx in row_indices:\n",
    "                    neighbor_key = self.adata.obs_names[neighbor_global_idx]\n",
    "                    if neighbor_key in key_to_local_idx:\n",
    "                        # 确保只添加子图内部的边\n",
    "                        j = key_to_local_idx[neighbor_key]\n",
    "                        edge_list.append([i, j])\n",
    "\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous() if edge_list else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "            return PyGData(\n",
    "                x_image=torch.stack(images),\n",
    "                x_text=tokenized_texts,\n",
    "                edge_index=edge_index,\n",
    "                num_nodes=num_nodes,\n",
    "                center_key=center_key,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Skipping sample {center_key} due to error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        pipeline = wds.DataPipeline(\n",
    "            wds.SimpleShardList(self.tar_urls) if not isinstance(self.tar_urls, wds.ShardList) else self.tar_urls,\n",
    "            wds.split_by_worker,\n",
    "            wds.tarfile_to_samples(),\n",
    "            wds.decode(\"pilrgb\", \"txt\"),\n",
    "            wds.map(self._process_sample),\n",
    "            wds.select(lambda x: x is not None),\n",
    "        )\n",
    "        return iter(pipeline)\n",
    "\n",
    "def get_spaglam_dataset(args, preprocess_fn, is_train, epoch=0, tokenizer=None):\n",
    "    input_shards = args.train_data\n",
    "    dataset = SpaGLaMWDataset(\n",
    "        tar_urls=input_shards,\n",
    "        anndata_path=args.anndata_path,\n",
    "        image_processor=preprocess_fn,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.workers,\n",
    "        collate_fn=PyGBatch.from_data_list,\n",
    "        drop_last=is_train,\n",
    "    )\n",
    "    # 模拟附加元数据\n",
    "    dataloader.num_samples = args.train_num_samples\n",
    "    if dataloader.num_samples:\n",
    "        dataloader.num_batches = dataloader.num_samples // args.batch_size\n",
    "    else:\n",
    "        dataloader.num_batches = 0\n",
    "    return DataInfo(dataloader=dataloader)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 这是您计划修改的 src/open_clip_train/data.py 的核心部分\n",
    "# -------------------------------------------------------------\n",
    "def get_dataset_fn(data_path, dataset_type):\n",
    "    if dataset_type == \"spaglam\":\n",
    "        return get_spaglam_dataset\n",
    "    # 在这个测试中我们不关心其他类型\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset type for this test: {dataset_type}\")\n",
    "\n",
    "def get_data(args, preprocess_fns, epoch=0, tokenizer=None):\n",
    "    preprocess_train, preprocess_val = preprocess_fns\n",
    "    data = {}\n",
    "    if args.train_data:\n",
    "        data[\"train\"] = get_dataset_fn(args.train_data, args.dataset_type)(\n",
    "            args, preprocess_train, is_train=True, epoch=epoch, tokenizer=tokenizer)\n",
    "    return data\n",
    "\n",
    "print(\"✅ 核心数据处理代码已加载到Notebook中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef816aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模拟参数 ---\n",
      "dataset_type: spaglam\n",
      "train_data: ['/cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment/shards/shard-000000.tar']\n",
      "anndata_path: /cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment/metadata/dummy_master_adata.h5ad\n",
      "train_num_samples: 100\n",
      "batch_size: 4\n",
      "workers: 0\n",
      "world_size: 1\n",
      "distributed: False\n",
      "\n",
      "✅ 模拟的预处理器和分词器已准备就绪。\n",
      "\n",
      "--- 调用 get_data() ---\n",
      "✅ 成功创建DataLoader！\n",
      "\n",
      "--- 最终验证：从DataLoader中获取一个批次 ---\n",
      "\n",
      "❌ [失败] 在获取或验证批次时发生错误: module 'webdataset' has no attribute 'ShardList'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_152893/2261647055.py\", line 41, in <module>\n",
      "    batch = next(iter(dataloader))\n",
      "                 ~~~~^^^^^^^^^^^^\n",
      "  File \"/public/home/jijh/micromamba/envs/gigapath/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 491, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/public/home/jijh/micromamba/envs/gigapath/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 419, in _get_iterator\n",
      "    return _SingleProcessDataLoaderIter(self)\n",
      "  File \"/public/home/jijh/micromamba/envs/gigapath/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 754, in __init__\n",
      "    self._dataset_fetcher = _DatasetKind.create_fetcher(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._dataset_kind,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        self._drop_last,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/public/home/jijh/micromamba/envs/gigapath/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 81, in create_fetcher\n",
      "    return _utils.fetch._IterableDatasetFetcher(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        dataset, auto_collation, collate_fn, drop_last\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/public/home/jijh/micromamba/envs/gigapath/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 22, in __init__\n",
      "    self.dataset_iter = iter(dataset)\n",
      "                        ~~~~^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_152893/3162152864.py\", line 84, in __iter__\n",
      "    wds.SimpleShardList(self.tar_urls) if not isinstance(self.tar_urls, wds.ShardList) else self.tar_urls,\n",
      "                                                                        ^^^^^^^^^^^^^\n",
      "AttributeError: module 'webdataset' has no attribute 'ShardList'. Did you mean: 'shardlists'?\n"
     ]
    }
   ],
   "source": [
    "# 单元格 4: 模拟训练脚本的调用并验证输出\n",
    "\n",
    "# --- 1. 模拟命令行参数 (args) ---\n",
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    dataset_type='spaglam',\n",
    "    train_data=[DUMMY_SHARD_PATH_PATTERN % 0], # 使用我们创建的模拟分片\n",
    "    anndata_path=DUMMY_ADATA_PATH,            # 使用我们创建的模拟AnnData\n",
    "    train_num_samples=NUM_SPOTS,\n",
    "    batch_size=4,\n",
    "    workers=0, # 关键：在notebook中设为0，以便于调试，避免多进程问题\n",
    "    world_size=1,\n",
    "    distributed=False\n",
    ")\n",
    "print(\"--- 模拟参数 ---\")\n",
    "for k, v in vars(args).items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# --- 2. 模拟预处理器和分词器 ---\n",
    "from torchvision import transforms\n",
    "dummy_preprocess_fn = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 一个非常简单的分词器，返回固定长度的随机整数张量\n",
    "dummy_tokenizer = lambda texts: torch.randint(0, 49408, (len(texts), 77), dtype=torch.long)\n",
    "print(\"\\n✅ 模拟的预处理器和分词器已准备就绪。\")\n",
    "\n",
    "\n",
    "# --- 3. 调用 get_data 获取 DataLoader ---\n",
    "print(\"\\n--- 调用 get_data() ---\")\n",
    "data = get_data(args, (dummy_preprocess_fn, None), tokenizer=dummy_tokenizer)\n",
    "dataloader = data['train'].dataloader\n",
    "print(\"✅ 成功创建DataLoader！\")\n",
    "\n",
    "# --- 4. 从DataLoader中取出一个批次并进行最终验证 ---\n",
    "print(\"\\n--- 最终验证：从DataLoader中获取一个批次 ---\")\n",
    "try:\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "    print(\"\\n✅ [成功] 成功从DataLoader中获取一个批次的数据！\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # --- 验证 1: 检查批次类型 ---\n",
    "    print(f\"批次类型: {type(batch)}\")\n",
    "    assert isinstance(batch, PyGBatch), \"批次类型不正确！应为 torch_geometric.data.Batch\"\n",
    "    print(\"✅ [类型正确] 批次是 torch_geometric.data.Batch 对象。\")\n",
    "    \n",
    "    # --- 验证 2: 检查批次内容 ---\n",
    "    print(\"\\n批次内容概览:\")\n",
    "    print(batch)\n",
    "    \n",
    "    # --- 验证 3: 检查关键属性 ---\n",
    "    print(\"\\n关键属性检查:\")\n",
    "    print(f\"批次中的图数量 (应等于batch_size): {batch.num_graphs}\")\n",
    "    assert batch.num_graphs == args.batch_size, \"批次中的图数量不等于batch_size\"\n",
    "    \n",
    "    total_nodes = sum([NUM_NEIGHBORS + 1] * args.batch_size) # 理论上的节点总数\n",
    "    print(f\"批次中的节点总数: {batch.num_nodes}\")\n",
    "    # 注意：由于某些邻居可能缺失，实际节点数可能略小于理论值，这里不作严格断言\n",
    "    \n",
    "    print(f\"x_image 张量形状: {batch.x_image.shape}\")\n",
    "    assert batch.x_image.shape[0] == batch.num_nodes\n",
    "    assert tuple(batch.x_image.shape[1:]) == (3, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "    \n",
    "    print(f\"x_text 张量形状: {batch.x_text.shape}\")\n",
    "    assert batch.x_text.shape[0] == batch.num_nodes\n",
    "    \n",
    "    print(f\"edge_index 张量形状: {batch.edge_index.shape}\")\n",
    "    \n",
    "    print(f\"batch 索引向量长度 (应等于节点总数): {len(batch.batch)}\")\n",
    "    assert len(batch.batch) == batch.num_nodes\n",
    "    \n",
    "    print(\"\\n✅ [内容正确] 批次对象的所有关键属性都符合预期！\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\n🎉🎉🎉 恭喜！数据加载管道验证成功！您可以放心地将这些代码集成到open-clip项目中了。🎉🎉🎉\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ [失败] 在获取或验证批次时发生错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceabe17",
   "metadata": {},
   "source": [
    "# 修复错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1340fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 核心数据处理代码已加载到Notebook中 (最终修复版)。\n"
     ]
    }
   ],
   "source": [
    "# 单元格 3: 复制并粘贴我们正在测试的核心代码 (最终修复版)\n",
    "\n",
    "import logging\n",
    "import scanpy as sc\n",
    "import webdataset as wds\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch_geometric.data import Data as PyGData, Batch as PyGBatch\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 这是您计划放在 src/open_clip_train/spaglam_data.py 的代码\n",
    "# -------------------------------------------------------------\n",
    "class SpaGLaMWDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, tar_urls, anndata_path, image_processor, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tar_urls = tar_urls\n",
    "        self.anndata_path = anndata_path\n",
    "        self.image_processor = image_processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.adata = None\n",
    "\n",
    "    def _init_worker(self):\n",
    "        if self.adata is None:\n",
    "            self.adata = sc.read_h5ad(self.anndata_path, backed='r')\n",
    "\n",
    "    def _process_sample(self, sample):\n",
    "        self._init_worker()\n",
    "        center_key = sample['__key__']\n",
    "        \n",
    "        try:\n",
    "            # 1. 解码中心点数据 (现在更加稳健)\n",
    "            center_img = sample['png'] # wds.decode(\"pilrgb\") 保证了这是一个PIL Image\n",
    "            \n",
    "            # ------------------- 文本解码最终修复点 -------------------\n",
    "            # 防御性编程：检查类型，因为webdataset可能已经自动解码了.txt文件\n",
    "            txt_data = sample['txt']\n",
    "            if isinstance(txt_data, bytes):\n",
    "                center_sent = txt_data.decode('utf-8')\n",
    "            else:\n",
    "                center_sent = txt_data  # 它已经是字符串了\n",
    "            # ---------------------------------------------------------\n",
    "\n",
    "            # 2. 从 AnnData 获取邻居信息\n",
    "            center_idx = self.adata.obs_names.get_loc(center_key)\n",
    "            neighbor_indices = self.adata.obsp['spatial_connectivities'][center_idx].indices\n",
    "            neighbor_keys = self.adata.obs_names[neighbor_indices].tolist()\n",
    "            \n",
    "            all_keys = [center_key] + neighbor_keys\n",
    "            num_nodes = len(all_keys)\n",
    "            \n",
    "            paths_df = self.adata.obs.loc[all_keys, ['image_path', 'sentence_path']]\n",
    "            \n",
    "            # 3. 加载所有节点的数据并预处理\n",
    "            images_processed, sentences = [], []\n",
    "            for key in all_keys:\n",
    "                if key == center_key:\n",
    "                    img = center_img\n",
    "                    sent = center_sent\n",
    "                else:\n",
    "                    img_path, sent_path = paths_df.loc[key]\n",
    "                    try: img = Image.open(img_path).convert(\"RGB\")\n",
    "                    except (FileNotFoundError, OSError): img = Image.new('RGB', (224, 224), color='grey')\n",
    "                    try: \n",
    "                        with open(sent_path, 'r') as f: sent = f.read()\n",
    "                    except (FileNotFoundError, OSError): sent = \"\"\n",
    "                \n",
    "                images_processed.append(self.image_processor(img))\n",
    "                sentences.append(sent)\n",
    "\n",
    "            tokenized_texts = self.tokenizer(sentences)\n",
    "            \n",
    "            # 4. 构建局部图结构\n",
    "            key_to_local_idx = {key: i for i, key in enumerate(all_keys)}\n",
    "            edge_list = []\n",
    "            \n",
    "            for i, key in enumerate(all_keys):\n",
    "                global_idx = self.adata.obs_names.get_loc(key)\n",
    "                row_indices = self.adata.obsp['spatial_connectivities'][global_idx].indices\n",
    "                \n",
    "                for neighbor_global_idx in row_indices:\n",
    "                    neighbor_key = self.adata.obs_names[neighbor_global_idx]\n",
    "                    if neighbor_key in key_to_local_idx:\n",
    "                        j = key_to_local_idx[neighbor_key]\n",
    "                        if i < j:\n",
    "                            edge_list.append([i, j])\n",
    "                            edge_list.append([j, i])\n",
    "\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous() if edge_list else torch.empty((2, 0), dtype=torch.long)\n",
    "            \n",
    "            # 5. 返回PyG Data对象\n",
    "            return PyGData(\n",
    "                x_image=torch.stack(images_processed),\n",
    "                x_text=tokenized_texts,\n",
    "                edge_index=edge_index,\n",
    "                num_nodes=num_nodes,\n",
    "                center_key=center_key,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing sample {center_key}: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        pipeline = wds.DataPipeline(\n",
    "            wds.shardlists.SimpleShardList(self.tar_urls),\n",
    "            wds.split_by_worker,\n",
    "            wds.tarfile_to_samples(),\n",
    "            wds.decode(\"pilrgb\"), # 只解码图像，文本保持原样\n",
    "            wds.map(self._process_sample),\n",
    "            wds.select(lambda x: x is not None),\n",
    "        )\n",
    "        return iter(pipeline)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 其他代码 (get_spaglam_dataset, get_dataset_fn, get_data) 保持不变\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def get_spaglam_dataset(args, preprocess_fn, is_train, epoch=0, tokenizer=None):\n",
    "    # ... (此函数无需修改)\n",
    "    input_shards = args.train_data\n",
    "    dataset = SpaGLaMWDataset(\n",
    "        tar_urls=input_shards,\n",
    "        anndata_path=args.anndata_path,\n",
    "        image_processor=preprocess_fn,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.workers,\n",
    "        collate_fn=PyGBatch.from_data_list,\n",
    "        drop_last=is_train,\n",
    "    )\n",
    "    dataloader.num_samples = args.train_num_samples\n",
    "    if dataloader.num_samples:\n",
    "        dataloader.num_batches = dataloader.num_samples // args.batch_size\n",
    "    else:\n",
    "        dataloader.num_batches = 0\n",
    "    return DataInfo(dataloader=dataloader)\n",
    "\n",
    "def get_dataset_fn(data_path, dataset_type):\n",
    "    # ... (此函数无需修改)\n",
    "    if dataset_type == \"spaglam\":\n",
    "        return get_spaglam_dataset\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset type for this test: {dataset_type}\")\n",
    "\n",
    "def get_data(args, preprocess_fns, epoch=0, tokenizer=None):\n",
    "    # ... (此函数无需修改)\n",
    "    preprocess_train, preprocess_val = preprocess_fns\n",
    "    data = {}\n",
    "    if args.train_data:\n",
    "        data[\"train\"] = get_dataset_fn(args.train_data, args.dataset_type)(\n",
    "            args, preprocess_train, is_train=True, epoch=epoch, tokenizer=tokenizer)\n",
    "    return data\n",
    "\n",
    "print(\"✅ 核心数据处理代码已加载到Notebook中 (最终修复版)。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f82736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模拟参数 ---\n",
      "dataset_type: spaglam\n",
      "train_data: ['/cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment/shards/shard-000000.tar']\n",
      "anndata_path: /cwStorage/nodecw_group/jijh/openclip_train/spaglam_test_environment/metadata/dummy_master_adata.h5ad\n",
      "train_num_samples: 100\n",
      "batch_size: 4\n",
      "workers: 0\n",
      "world_size: 1\n",
      "distributed: False\n",
      "\n",
      "✅ 模拟的预处理器和分词器已准备就绪。\n",
      "\n",
      "--- 调用 get_data() ---\n",
      "✅ 成功创建DataLoader！\n",
      "\n",
      "--- 最终验证：从DataLoader中获取一个批次 ---\n",
      "\n",
      "✅ [成功] 成功从DataLoader中获取一个批次的数据！\n",
      "--------------------------------------------------\n",
      "批次类型: <class 'abc.DataBatch'>\n",
      "✅ [类型正确] 批次是 torch_geometric.data.Batch 对象。\n",
      "\n",
      "批次内容概览:\n",
      "DataBatch(edge_index=[2, 106], x_image=[28, 3, 224, 224], x_text=[28, 77], num_nodes=28, center_key=[4], batch=[28], ptr=[5])\n",
      "\n",
      "关键属性检查:\n",
      "批次中的图数量 (应等于batch_size): 4\n",
      "批次中的节点总数: 28\n",
      "x_image 张量形状: torch.Size([28, 3, 224, 224])\n",
      "x_text 张量形状: torch.Size([28, 77])\n",
      "edge_index 张量形状: torch.Size([2, 106])\n",
      "batch 索引向量长度 (应等于节点总数): 28\n",
      "\n",
      "✅ [内容正确] 批次对象的所有关键属性都符合预期！\n",
      "--------------------------------------------------\n",
      "\n",
      "🎉🎉🎉 恭喜！数据加载管道验证成功！您可以放心地将这些代码集成到open-clip项目中了。🎉🎉🎉\n"
     ]
    }
   ],
   "source": [
    "# 单元格 4: 模拟训练脚本的调用并验证输出\n",
    "\n",
    "# --- 1. 模拟命令行参数 (args) ---\n",
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    dataset_type='spaglam',\n",
    "    train_data=[DUMMY_SHARD_PATH_PATTERN % 0], # 使用我们创建的模拟分片\n",
    "    anndata_path=DUMMY_ADATA_PATH,            # 使用我们创建的模拟AnnData\n",
    "    train_num_samples=NUM_SPOTS,\n",
    "    batch_size=4,\n",
    "    workers=0, # 关键：在notebook中设为0，以便于调试，避免多进程问题\n",
    "    world_size=1,\n",
    "    distributed=False\n",
    ")\n",
    "print(\"--- 模拟参数 ---\")\n",
    "for k, v in vars(args).items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# --- 2. 模拟预处理器和分词器 ---\n",
    "from torchvision import transforms\n",
    "dummy_preprocess_fn = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 一个非常简单的分词器，返回固定长度的随机整数张量\n",
    "dummy_tokenizer = lambda texts: torch.randint(0, 49408, (len(texts), 77), dtype=torch.long)\n",
    "print(\"\\n✅ 模拟的预处理器和分词器已准备就绪。\")\n",
    "\n",
    "\n",
    "# --- 3. 调用 get_data 获取 DataLoader ---\n",
    "print(\"\\n--- 调用 get_data() ---\")\n",
    "data = get_data(args, (dummy_preprocess_fn, None), tokenizer=dummy_tokenizer)\n",
    "dataloader = data['train'].dataloader\n",
    "print(\"✅ 成功创建DataLoader！\")\n",
    "\n",
    "# --- 4. 从DataLoader中取出一个批次并进行最终验证 ---\n",
    "print(\"\\n--- 最终验证：从DataLoader中获取一个批次 ---\")\n",
    "try:\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "    print(\"\\n✅ [成功] 成功从DataLoader中获取一个批次的数据！\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # --- 验证 1: 检查批次类型 ---\n",
    "    print(f\"批次类型: {type(batch)}\")\n",
    "    assert isinstance(batch, PyGBatch), \"批次类型不正确！应为 torch_geometric.data.Batch\"\n",
    "    print(\"✅ [类型正确] 批次是 torch_geometric.data.Batch 对象。\")\n",
    "    \n",
    "    # --- 验证 2: 检查批次内容 ---\n",
    "    print(\"\\n批次内容概览:\")\n",
    "    print(batch)\n",
    "    \n",
    "    # --- 验证 3: 检查关键属性 ---\n",
    "    print(\"\\n关键属性检查:\")\n",
    "    print(f\"批次中的图数量 (应等于batch_size): {batch.num_graphs}\")\n",
    "    assert batch.num_graphs == args.batch_size, \"批次中的图数量不等于batch_size\"\n",
    "    \n",
    "    total_nodes = sum([NUM_NEIGHBORS + 1] * args.batch_size) # 理论上的节点总数\n",
    "    print(f\"批次中的节点总数: {batch.num_nodes}\")\n",
    "    # 注意：由于某些邻居可能缺失，实际节点数可能略小于理论值，这里不作严格断言\n",
    "    \n",
    "    print(f\"x_image 张量形状: {batch.x_image.shape}\")\n",
    "    assert batch.x_image.shape[0] == batch.num_nodes\n",
    "    assert tuple(batch.x_image.shape[1:]) == (3, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "    \n",
    "    print(f\"x_text 张量形状: {batch.x_text.shape}\")\n",
    "    assert batch.x_text.shape[0] == batch.num_nodes\n",
    "    \n",
    "    print(f\"edge_index 张量形状: {batch.edge_index.shape}\")\n",
    "    \n",
    "    print(f\"batch 索引向量长度 (应等于节点总数): {len(batch.batch)}\")\n",
    "    assert len(batch.batch) == batch.num_nodes\n",
    "    \n",
    "    print(\"\\n✅ [内容正确] 批次对象的所有关键属性都符合预期！\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\n🎉🎉🎉 恭喜！数据加载管道验证成功！您可以放心地将这些代码集成到open-clip项目中了。🎉🎉🎉\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ [失败] 在获取或验证批次时发生错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5457ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gigapath)",
   "language": "python",
   "name": "gigapath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
